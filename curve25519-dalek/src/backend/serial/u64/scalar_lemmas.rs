#[allow(unused_imports)]
use super::common_verus::*;
#[allow(unused_imports)]
use super::scalar::Scalar52;
#[allow(unused_imports)]
use super::scalar_specs::*;
#[allow(unused_imports)]
use vstd::arithmetic::div_mod::*;
#[allow(unused_imports)]
use vstd::arithmetic::mul::*;
#[allow(unused_imports)]
use vstd::arithmetic::power2::*;
#[allow(unused_imports)]
use vstd::bits::*;
#[allow(unused_imports)]
use vstd::calc;
use vstd::prelude::*;

verus! {

/// Verification: scalar * scalar.invert() â‰¡ 1 mod L
proof fn verify_invert_correct(x: Scalar52)
//     requires to_scalar(&x.limbs) != 0
//    ensures (to_scalar(&x.limbs) * invert_spec(&x.limbs)) % group_order() == 1
{
    assume(false);

}

pub proof fn lemma_52_52(x: u64, y: u64)
requires
    x < (1u64 << 52),
    y < (1u64 << 52),
ensures (x as u128) * (y as u128) < (1u128 << 104)
{
    assert(1u128 << 52 == 1u64 << 52) by (bit_vector);
    calc! {
        (<)
        (x as u128) * (y as u128); (<=) {
            if x > 0 {
                lemma_mul_strict_inequality(y as int, (1u128 << 52) as int, x as int);
                assert( x * y < x * (1u128 << 52)  );
            } else {
                assert((0 as u128) * (y as u128) == 0);
            }
        }
        (x as u128) * (1u128 << 52); (<) {
            lemma_mul_strict_inequality(x as int, (1u128 << 52) as int, (1u128 << 52) as int);
        }
        (1u128 << 52) * (1u128 << 52);
    }
    assert((1u128 << 52) * (1u128 << 52) == (1u128 << 104)) by (compute);
}

pub proof fn lemma_square_internal_no_overflow()
    ensures
         (1u128 << 105) + (1u128 << 105) == (1u128 << 106),
         (1u128 << 105) + (1u128 << 104) < (1u128 << 106),
         (1u128 << 104) * 2 == (1u128 << 105),
         (1u128 << 106) + (1u128 << 104) < (1u128 << 107),
{
    assert((1u128 << 105) + (1u128 << 105) == (1u128 << 106)) by (bit_vector);
    assert((1u128 << 105) + (1u128 << 104) < (1u128 << 106)) by (bit_vector);
    assert((1u128 << 104) * 2 == (1u128 << 105)) by (bit_vector);
    assert((1u128 << 106) + (1u128 << 104) < (1u128 << 107)) by (bit_vector);
}


pub proof fn lemma_square_internal_correct(a: &[u64; 5], z: &[u128; 9])
    requires
        forall|i: int| 0 <= i < 5 ==> a[i] < (1u64 << 52),
        z[0] == (a[0] * a[0]) ,
        z[1] == (a[0] * a[1])  * 2,
        z[2] == (a[0] * a[2])  * 2 + (a[1] * a[1]) ,
        z[3] == (a[0] * a[3])  * 2 + (a[1] * a[2])  * 2,
        z[4] == (a[0] * a[4])  * 2 + (a[1] * a[3])  * 2 + (a[2] * a[2]) ,
        z[5] == (a[1] * a[4])  * 2 + (a[2] * a[3])  * 2,
        z[6] == (a[2] * a[4])  * 2 + (a[3] * a[3]) ,
        z[7] == (a[3] * a[4])  * 2,
        z[8] == (a[4] * a[4]) ,
    ensures
        slice128_to_nat(z) == to_nat(a) * to_nat(a),

{
        assert(five_limbs_to_nat_aux(*a) * five_limbs_to_nat_aux(*a) == nine_limbs_to_nat_aux(&z)) by {
            broadcast use group_mul_is_commutative_and_distributive;
            broadcast use lemma_mul_is_associative;

            lemma_pow2_adds(52, 52);
            lemma_pow2_adds(52, 104);
            lemma_pow2_adds(52, 156);
            lemma_pow2_adds(52, 208);
            lemma_pow2_adds(104, 104);
            lemma_pow2_adds(104, 156);
            lemma_pow2_adds(104, 208);
            lemma_pow2_adds(156, 156);
            lemma_pow2_adds(156, 208);
            lemma_pow2_adds(208, 208);
        };
        lemma_nine_limbs_equals_slice128_to_nat(&z);
        lemma_five_limbs_equals_to_nat(&a);
}

pub proof fn lemma_mul_internal_no_overflow()
    ensures
        (1u128 << 104) + (1u128 << 104) == (1u128 << 105),
        3u128 * (1u128 << 104) < (1u128 << 106),
        4u128 * (1u128 << 104) == (1u128 << 2) * (1u128 << 104),
        (1u128 << 2) * (1u128 << 104) == (1u128 << 106),
        8u128 == (1u128 << 3),
        (1u128 << 3) * (1u128 << 104) == (1u128 << 107),
{
    assert((1u128 << 104) + (1u128 << 104) == (1u128 << 105)) by (bit_vector);
    assert(3u128 * (1u128 << 104) < (1u128 << 106)) by (bit_vector);
    assert(4u128 * (1u128 << 104) == (1u128 << 2) * (1u128 << 104)) by (bit_vector);
    assert((1u128 << 2) * (1u128 << 104) == (1u128 << 106)) by (bit_vector);
    assert(8u128 == (1u128 << 3)) by (bit_vector);
    assert((1u128 << 3) * (1u128 << 104) == (1u128 << 107)) by (bit_vector);
}

pub proof fn lemma_mul_internal_correct(a: &[u64; 5], b: &[u64; 5], z: &[u128; 9])
    requires
        forall|i: int| 0 <= i < 5 ==> a[i] < (1u64 << 52),
        forall|i: int| 0 <= i < 5 ==> b[i] < (1u64 << 52),
        z[0] == (a[0] * b[0]),
        z[1] == (a[0] * b[1]) + (a[1] * b[0]),
        z[2] == (a[0] * b[2]) + (a[1] * b[1]) + (a[2] * b[0]),
        z[3] == (a[0] * b[3]) + (a[1] * b[2]) + (a[2] * b[1]) + (a[3] * b[0]),
        z[4] == (a[0] * b[4]) + (a[1] * b[3]) + (a[2] * b[2]) + (a[3] * b[1]) + (a[4] * b[0]),
        z[5] == (a[1] * b[4]) + (a[2] * b[3]) + (a[3] * b[2]) + (a[4] * b[1]),
        z[6] == (a[2] * b[4]) + (a[3] * b[3]) + (a[4] * b[2]),
        z[7] == (a[3] * b[4]) + (a[4] * b[3]),
        z[8] == (a[4] * b[4]),
    ensures
        slice128_to_nat(z) == to_nat(a) * to_nat(b),
{
    assert(five_limbs_to_nat_aux(*a) * five_limbs_to_nat_aux(*b) == nine_limbs_to_nat_aux(&z)) by {
        broadcast use group_mul_is_commutative_and_distributive;
        broadcast use lemma_mul_is_associative;

        lemma_pow2_adds(52, 52);
        lemma_pow2_adds(52, 104);
        lemma_pow2_adds(52, 156);
        lemma_pow2_adds(52, 208);
        lemma_pow2_adds(104, 104);
        lemma_pow2_adds(104, 156);
        lemma_pow2_adds(104, 208);
        lemma_pow2_adds(156, 156);
        lemma_pow2_adds(156, 208);
        lemma_pow2_adds(208, 208);
    };
    lemma_nine_limbs_equals_slice128_to_nat(&z);
    lemma_five_limbs_equals_to_nat(&a);
    lemma_five_limbs_equals_to_nat(&b);
}


pub proof fn lemma_nine_limbs_equals_slice128_to_nat(limbs: &[u128; 9])
ensures
    nine_limbs_to_nat_aux(limbs) == slice128_to_nat(limbs)
{

    let seq = limbs@.map(|i, x| x as nat);

    calc! {
        (==)
        slice128_to_nat(limbs); {
        }
        seq_to_nat(seq); {
            reveal_with_fuel(seq_to_nat, 10);
        }
        (limbs[0] as nat) +
        ((limbs[1] as nat) +
            ((limbs[2] as nat) +
            ((limbs[3] as nat) +
            ((limbs[4] as nat) +
            ((limbs[5] as nat) +
                ((limbs[6] as nat) +
                ((limbs[7] as nat) +
                (limbs[8] as nat) * pow2(52)
                ) * pow2(52)
                ) * pow2(52)
            ) * pow2(52)
            ) * pow2(52)
            ) * pow2(52)
            ) * pow2(52)
        ) * pow2(52); {
        lemma_pow2_adds(52, 52);
        lemma_pow2_adds(104, 52);
        lemma_pow2_adds(156, 52);
        lemma_pow2_adds(208, 52);
        lemma_pow2_adds(260, 52);
        lemma_pow2_adds(312, 52);
        lemma_pow2_adds(364, 52);
        broadcast use group_mul_is_distributive;
        broadcast use lemma_mul_is_associative;
        }
        nine_limbs_to_nat_aux(limbs);
    }
}

pub proof fn lemma_five_limbs_equals_to_nat(limbs: &[u64; 5])
ensures
    five_limbs_to_nat_aux(*limbs) == to_nat(limbs)
{
    let seq = limbs@.map(|i, x| x as nat);

    calc! {
        (==)
        to_nat(limbs); {
        }
        seq_to_nat(seq); {
            reveal_with_fuel(seq_to_nat, 6);
        }
        (limbs[0] as nat) +
        ((limbs[1] as nat) +
            ((limbs[2] as nat) +
            ((limbs[3] as nat) +
            (limbs[4] as nat) * pow2(52)
            ) * pow2(52)
            ) * pow2(52)
        ) * pow2(52); {
        lemma_pow2_adds(52, 52);
        lemma_pow2_adds(104, 52);
        lemma_pow2_adds(156, 52);
        broadcast use group_mul_is_distributive;
        broadcast use lemma_mul_is_associative;
        }
        (limbs[0] as nat) +
        pow2(52) * (limbs[1] as nat) +
        pow2(104) * (limbs[2] as nat) +
        pow2(156) * (limbs[3] as nat) +
        pow2(208) * (limbs[4] as nat); {
        }
        five_limbs_to_nat_aux(*limbs);
    }
}


pub proof fn lemma_scalar_subtract_no_overflow(carry: u64, difference_limb: u64, addend: u64, i: u32, l_value: &Scalar52)
    requires
        i < 5,
        difference_limb < (1u64 << 52),
        addend == 0 || addend == l_value.limbs[i as int],
        i == 0 ==> carry == 0,
        i >= 1 ==> (carry >> 52) < 2,
        l_value.limbs[0] == 0x0002631a5cf5d3ed,
        l_value.limbs[1] == 0x000dea2f79cd6581,
        l_value.limbs[2] == 0x000000000014def9,
        l_value.limbs[3] == 0x0000000000000000,
        l_value.limbs[4] == 0x0000100000000000,
    ensures
        (carry >> 52) + difference_limb + addend < (1u64 << 53),
{
    if i == 0 {
        assert(0x0002631a5cf5d3ed < (1u64 << 52)) by (bit_vector);
    } else if i == 1 {
        assert(0x000dea2f79cd6581 < (1u64 << 52)) by (bit_vector);
    } else if i == 2 {
        assert(0x000000000014def9 < (1u64 << 52)) by (bit_vector);
    } else if i == 3 {
    } else {
        assert(0x0000100000000000 < (1u64 << 52)) by (bit_vector);
    }
    if i == 0 {
        assert((0u64 >> 52) == 0) by (bit_vector);
    }
    assert(2 * (1u64 << 52) == (1u64 << 53)) by (bit_vector);
}

pub proof fn lemma_borrow_and_mask_bounded(borrow: u64, mask: u64)
    requires
        mask == (1u64 << 52) - 1,
    ensures
        (borrow & mask) < (1u64 << 52),
{
    assert((borrow & mask) <= mask) by (bit_vector);
}

pub proof fn lemma_carry_bounded_after_mask(carry: u64, mask: u64)
    requires
        mask == (1u64 << 52) - 1,
        carry < (1u64 << 53),
    ensures
        (carry & mask) < (1u64 << 52),
        (carry >> 52) <= 1,
{
    assert((carry & mask) <= mask) by (bit_vector);
    assert((1u64 << 53) == 2 * (1u64 << 52)) by (bit_vector);
    broadcast use lemma_u64_shr_is_div;
    lemma_pow2_pos(52);
    shift_is_pow2(52);
    assert(carry >> 52 == carry / (1u64 << 52));
    lemma_fundamental_div_mod(carry as int, (1u64 << 52) as int);
    let q = carry / (1u64 << 52);
    let r = carry % (1u64 << 52);
    lemma_mul_strict_inequality_converse(q as int, 2int, (1u64 << 52) as int);
}

pub proof fn lemma_add_loop_bounds(i: int, carry: u64, a_limb: u64, b_limb: u64)
    requires
        0 <= i < 5,
        a_limb < (1u64 << 52),
        b_limb < (1u64 << 52),
        i == 0 ==> carry == 0,
        i >= 1 ==> (carry >> 52) < 2,
    ensures
        (carry >> 52) + a_limb + b_limb < (1u64 << 53),
{
    if i == 0 {
        assert((0u64 >> 52) == 0) by (bit_vector);
    }
    assert((1u64 << 52) + (1u64 << 52) == (1u64 << 53)) by (bit_vector);
}

pub proof fn lemma_add_carry_and_sum_bounds(carry: u64, mask: u64)
    requires
        mask == (1u64 << 52) - 1,
        carry < (1u64 << 53),
    ensures
        (carry & mask) < (1u64 << 52),
        (carry >> 52) < 2,
{
    assert((carry & mask) <= mask) by (bit_vector);
    assert((1u64 << 53) == 2 * (1u64 << 52)) by (bit_vector);
    broadcast use lemma_u64_shr_is_div;
    lemma_pow2_pos(52);
    shift_is_pow2(52);
    assert(carry >> 52 == carry / (1u64 << 52));
    lemma_fundamental_div_mod(carry as int, (1u64 << 52) as int);
    let q = carry / (1u64 << 52);
    let r = carry % (1u64 << 52);
    lemma_mul_strict_inequality_converse(q as int, 2int, (1u64 << 52) as int);
}

pub proof fn lemma_l_value_properties(l_value: &Scalar52, sum: &Scalar52)
    requires
        l_value.limbs[0] == 0x0002631a5cf5d3ed,
        l_value.limbs[1] == 0x000dea2f79cd6581,
        l_value.limbs[2] == 0x000000000014def9,
        l_value.limbs[3] == 0x0000000000000000,
        l_value.limbs[4] == 0x0000100000000000,
        forall|j: int| 0 <= j < 5 ==> sum.limbs[j] < (1u64 << 52),
    ensures
        forall|j: int| 0 <= j < 5 ==> l_value.limbs[j] < (1u64 << 52),
{
    assert(0x0002631a5cf5d3ed < (1u64 << 52)) by (bit_vector);
    assert(0x000dea2f79cd6581 < (1u64 << 52)) by (bit_vector);
}


pub proof fn lemma_from_montgomery_limbs_conversion(
    limbs: &[u128; 9],
    self_limbs: &[u64; 5]
)
    requires
        forall|j: int| 0 <= j < 5 ==> limbs[j] == self_limbs[j] as u128,
        forall|j: int| 5 <= j < 9 ==> limbs[j] == 0,
    ensures
        slice128_to_nat(limbs) == to_nat(self_limbs),
{
    // Use the auxiliary function approach since it's easier to reason about
    lemma_nine_limbs_equals_slice128_to_nat(limbs);
    lemma_five_limbs_equals_to_nat(self_limbs);
    
    // Now we need to prove: nine_limbs_to_nat_aux(limbs) == five_limbs_to_nat_aux(*self_limbs)
    assert(nine_limbs_to_nat_aux(limbs) == 
           (limbs[0] as nat) +
           (limbs[1] as nat) * pow2(52) +
           (limbs[2] as nat) * pow2(104) +
           (limbs[3] as nat) * pow2(156) +
           (limbs[4] as nat) * pow2(208) +
           (limbs[5] as nat) * pow2(260) +
           (limbs[6] as nat) * pow2(312) +
           (limbs[7] as nat) * pow2(364) +
           (limbs[8] as nat) * pow2(416));
    
    assert(five_limbs_to_nat_aux(*self_limbs) ==
           (self_limbs[0] as nat) +
           pow2(52) * (self_limbs[1] as nat) +
           pow2(104) * (self_limbs[2] as nat) +
           pow2(156) * (self_limbs[3] as nat) +
           pow2(208) * (self_limbs[4] as nat));
    
    // Since limbs[5..8] are all 0 and limbs[0..4] == self_limbs[0..4], the sums are equal
    assert(limbs[5] == 0 && limbs[6] == 0 && limbs[7] == 0 && limbs[8] == 0);
    assert(forall|j: int| 0 <= j < 5 ==> limbs[j] == self_limbs[j] as u128);
    
    // Expand the equation step by step
    assert(limbs[0] == self_limbs[0] as u128);
    assert(limbs[1] == self_limbs[1] as u128);
    assert(limbs[2] == self_limbs[2] as u128);
    assert(limbs[3] == self_limbs[3] as u128);
    assert(limbs[4] == self_limbs[4] as u128);
    
    // The nine_limbs expansion with zeros in the high positions equals the five_limbs expansion
    assert(nine_limbs_to_nat_aux(limbs) == 
           (self_limbs[0] as nat) +
           (self_limbs[1] as nat) * pow2(52) +
           (self_limbs[2] as nat) * pow2(104) +
           (self_limbs[3] as nat) * pow2(156) +
           (self_limbs[4] as nat) * pow2(208) +
           0 * pow2(260) +
           0 * pow2(312) +
           0 * pow2(364) +
           0 * pow2(416));
           
    assert(nine_limbs_to_nat_aux(limbs) == five_limbs_to_nat_aux(*self_limbs));
}



pub proof fn lemma_rr_limbs_bounded()
    ensures
        0x0009d265e952d13bu64 < (1u64 << 52),
        0x000d63c715bea69fu64 < (1u64 << 52),
        0x0005be65cb687604u64 < (1u64 << 52),
        0x0003dceec73d217fu64 < (1u64 << 52),
        0x000009411b7c309au64 < (1u64 << 52),
{
    assert(0x0009d265e952d13bu64 < (1u64 << 52)) by (bit_vector);
    assert(0x000d63c715bea69fu64 < (1u64 << 52)) by (bit_vector);
    assert(0x0005be65cb687604u64 < (1u64 << 52)) by (bit_vector);
    assert(0x0003dceec73d217fu64 < (1u64 << 52)) by (bit_vector);
    assert(0x000009411b7c309au64 < (1u64 << 52)) by (bit_vector);
}

pub proof fn lemma_rr_constants_to_nat(rr_limbs: &[u64; 5])
    requires
        rr_limbs[0] == 0x0009d265e952d13bu64,
        rr_limbs[1] == 0x000d63c715bea69fu64,
        rr_limbs[2] == 0x0005be65cb687604u64,
        rr_limbs[3] == 0x0003dceec73d217fu64,
        rr_limbs[4] == 0x000009411b7c309au64,
    ensures
        to_nat(rr_limbs) == 
        ((0x0009d265e952d13bu64 as nat) +
         pow2(52) * (0x000d63c715bea69fu64 as nat) +
         pow2(104) * (0x0005be65cb687604u64 as nat) +
         pow2(156) * (0x0003dceec73d217fu64 as nat) +
         pow2(208) * (0x000009411b7c309au64 as nat)),
{
    lemma_five_limbs_equals_to_nat(rr_limbs);
    assert(to_nat(rr_limbs) == five_limbs_to_nat_aux(*rr_limbs));
}



} // verus!
